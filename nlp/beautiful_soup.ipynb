{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Beautiful-Soup---Web-Scraping\" data-toc-modified-id=\"Beautiful-Soup---Web-Scraping-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Beautiful Soup - Web Scraping</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-Beautiful-Soup?\" data-toc-modified-id=\"What-is-Beautiful-Soup?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><strong><font color=\"red\">What is Beautiful Soup?</font></strong></a></span></li><li><span><a href=\"#So-What-Do-I-Do-With-Beautiful-Soup?\" data-toc-modified-id=\"So-What-Do-I-Do-With-Beautiful-Soup?-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><strong><font color=\"orange\">So What Do I Do With Beautiful Soup?</font></strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#HTML-Elements\" data-toc-modified-id=\"HTML-Elements-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span><strong><font color=\"purple\">HTML Elements</font></strong></a></span></li><li><span><a href=\"#HTML-Terms\" data-toc-modified-id=\"HTML-Terms-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span><strong><font color=\"purple\">HTML Terms</font></strong></a></span></li><li><span><a href=\"#HTML-Properties-and-Attributes\" data-toc-modified-id=\"HTML-Properties-and-Attributes-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span><strong><font color=\"purple\">HTML Properties and Attributes</font></strong></a></span></li></ul></li><li><span><a href=\"#Now-What?\" data-toc-modified-id=\"Now-What?-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><strong><font color=\"green\">Now What?</font></strong></a></span></li><li><span><a href=\"#Codeup-Blogs\" data-toc-modified-id=\"Codeup-Blogs-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><strong><font color=\"blue\">Codeup Blogs</font></strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Grab-Title-from-Page\" data-toc-modified-id=\"Grab-Title-from-Page-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span><strong><font color=\"purple\">Grab Title from Page</font></strong></a></span></li><li><span><a href=\"#Grab-Text-from-Page\" data-toc-modified-id=\"Grab-Text-from-Page-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span><strong><font color=\"purple\">Grab Text from Page</font></strong></a></span></li><li><span><a href=\"#Build-Blog-Function\" data-toc-modified-id=\"Build-Blog-Function-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span><strong><font color=\"purple\">Build Blog Function</font></strong></a></span></li><li><span><a href=\"#Test-Function\" data-toc-modified-id=\"Test-Function-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span><strong><font color=\"purple\">Test Function</font></strong></a></span></li><li><span><a href=\"#Bonus-URL-Scrape\" data-toc-modified-id=\"Bonus-URL-Scrape-1.4.5\"><span class=\"toc-item-num\">1.4.5&nbsp;&nbsp;</span><strong><font color=\"purple\">Bonus URL Scrape</font></strong></a></span></li><li><span><a href=\"#Bonus-URL-Function\" data-toc-modified-id=\"Bonus-URL-Function-1.4.6\"><span class=\"toc-item-num\">1.4.6&nbsp;&nbsp;</span><strong><font color=\"purple\">Bonus URL Function</font></strong></a></span></li></ul></li><li><span><a href=\"#Inshorts-News-Articles\" data-toc-modified-id=\"Inshorts-News-Articles-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span><strong><font color=\"blue\">Inshorts News Articles</font></strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Scrape-Article-News-Cards\" data-toc-modified-id=\"Scrape-Article-News-Cards-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span><strong><font color=\"purple\">Scrape Article News Cards</font></strong></a></span></li><li><span><a href=\"#Scrape-the-Title-from-Each-News-Cards\" data-toc-modified-id=\"Scrape-the-Title-from-Each-News-Cards-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span><strong><font color=\"purple\">Scrape the Title from Each News Cards</font></strong></a></span></li><li><span><a href=\"#Scrape-Author-from-News-Cards\" data-toc-modified-id=\"Scrape-Author-from-News-Cards-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span><strong><font color=\"purple\">Scrape Author from News Cards</font></strong></a></span></li><li><span><a href=\"#Scrape-Text-from-Article-Page\" data-toc-modified-id=\"Scrape-Text-from-Article-Page-1.5.4\"><span class=\"toc-item-num\">1.5.4&nbsp;&nbsp;</span><strong><font color=\"purple\">Scrape Text from Article Page</font></strong></a></span></li><li><span><a href=\"#Scrape-Source-URL-from-News-Cards\" data-toc-modified-id=\"Scrape-Source-URL-from-News-Cards-1.5.5\"><span class=\"toc-item-num\">1.5.5&nbsp;&nbsp;</span><strong><font color=\"purple\">Scrape Source URL from News Cards</font></strong></a></span></li><li><span><a href=\"#Build-Article-Function\" data-toc-modified-id=\"Build-Article-Function-1.5.6\"><span class=\"toc-item-num\">1.5.6&nbsp;&nbsp;</span><strong><font color=\"purple\">Build Article Function</font></strong></a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from requests import get\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup - Web Scraping\n",
    "\n",
    "#### **<font color=red>What is Beautiful Soup?</font>**\n",
    "\n",
    "\n",
    "\n",
    "#### **<font color=orange>So What Do I Do With Beautiful Soup?</font>**\n",
    "\n",
    "Here, we are looking to retrieve content from a web page, but the web page is written in HTML (HyperText Markup Language), so we need a basic understanding of the different HTML elements used to create web pages.\n",
    "\n",
    "##### **<font color=purple>HTML Elements</font>**\n",
    "\n",
    "`<html>` tag identifies all contents as html\n",
    "\n",
    "`<head>` tag contains data about the title of the web page\n",
    "\n",
    "`<body>` tag contains the main content of the web page\n",
    "\n",
    "`<p>` or paragraph tag creates new pargraphs of text\n",
    "\n",
    "`<a>` tag (tell the browser to render a link). `<a>` tags use the `href` property to tell the link where to go.\n",
    "\n",
    "`<div>` tag indentifies a division of the page\n",
    "\n",
    "`<b>` tag bolds the text inside\n",
    "\n",
    "`<i>` tag italicizes the text inside\n",
    "\n",
    "`<table>` tag creates a table\n",
    "\n",
    "`<form>` tag creates an input form\n",
    "   \n",
    "><font color=purple>The tags are nested inside of the main html tag like you see below.</font>\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "    <p>\n",
    "        <a href = \"link\", id='name_of_link'>\n",
    "    </p>\n",
    "    <p class=''>\n",
    "    </p>\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "##### **<font color=purple>HTML Terms</font>**\n",
    "\n",
    "**child** -> a tag inside of another tag. The `<p>` tags above are children of the `<body>` tag.\n",
    "\n",
    "**parent** -> the tag another tag is inside of. The `<body>` tag is the parent of the `<p>` tag.\n",
    "\n",
    "**sibling** -> a tag that is nested inside the same parent tag as another tag. The two `<p>` tags are siblings tags inside of the `<body>` tag.\n",
    "\n",
    "##### **<font color=purple>HTML Properties and Attributes</font>**\n",
    "\n",
    "These are optional, but they make the HTML elements easier to work with because they give the elements names. You will have to examine a web page to find out if it uses these properties.\n",
    "\n",
    "`class` is a property of an HTML element. One element can have multiple classes and elements can share the same classes, so classes cannot be used as unique identifiers.\n",
    "\n",
    "`id` is a property of an HTML element. Each element can only have one id, so they can be used as unique identifiers.\n",
    "\n",
    "`itemprop` is an attribute that consists of a name-value pair and is used to add properties to an item.\n",
    "\n",
    "#### **<font color=green>Now What?</font>**\n",
    "\n",
    "We will need to use the `requests` library to retrieve the HTML from a web page we want to scrape. You can review how to use the `requests` library in my notebook [here](https://faithkane3.github.io/time_series_review/time_series_review).\n",
    "\n",
    "Next, we will inspect the structure of the web page by right-clicking on the page we want to scrape and clicking 'inspect'. This will allow us to move our cursor over the part of the page we want to scrape and see the responsible HTML code for that section high-lighted on the right. We can use the tag and its properties with `BeautifulSoup` to `soup.find(name=tag)`\n",
    "\n",
    "We will need to use `BeautifulSoup` to parse the HTML response to our request. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {'User-Agent': 'Codeup Bayes Data Science'} \n",
    "    \n",
    "response = get(url, headers=headers)\n",
    "response.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's our long string; we'll use this to make our soup object\n",
    "\n",
    "print(type(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use BeautifulSoup using our response string\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Now we have our BeautifulSoup object, we can use its built-in methods and properties\n",
    "\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color=blue>Codeup Blogs</font>**\n",
    "\n",
    "**Goals:** Write a function to scrape urls from main Codeup blog web page and write a function that returns a dictionary of blog titles and text for each blog page. \n",
    "\n",
    "##### **<font color=purple>Grab Title from Page</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the find method on my soup passing in \n",
    "\n",
    "title = soup.find('h1', itemprop='headline' ).get_text()\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Grab Text from Page</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = soup.find('div', itemprop='text').get_text()\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Build Blog Function</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://codeup.com/codeups-data-science-career-accelerator-is-here/',\n",
    "            'https://codeup.com/data-science-myths/',\n",
    "            'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/',\n",
    "            'https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/',\n",
    "            'https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/']\n",
    "\n",
    "def get_blog_articles(urls):\n",
    "    '''\n",
    "    This function takes in a list of Codeup Blog urls and a dictionary headers \n",
    "    and scrapes the title and text for each url returning a list of dictionaries\n",
    "    with the title and text for each blog.\n",
    "    '''\n",
    "    headers = {'User-Agent': 'Codeup Bayes Data Science'} \n",
    "    \n",
    "    # Create an empty list to hold dictionaries\n",
    "    articles = []\n",
    "    \n",
    "    # Loop through each url in our list of urls\n",
    "    for url in urls:\n",
    "        \n",
    "        # get request to each url saved in response\n",
    "        response = get(url, headers=headers)\n",
    "        \n",
    "        # Create soup object from response text and parse\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Save the title of each blog in variable title\n",
    "        title = soup.find('h1', itemprop='headline' ).get_text()\n",
    "        \n",
    "        # Save the text in each blog to variable text\n",
    "        text = soup.find('div', itemprop='text').get_text()\n",
    "        \n",
    "        # Create a dictionary holding the title and text for each blog\n",
    "        article = {'title': title, 'content': text}\n",
    "        \n",
    "        # Add each dictionary to the articles list of dictionaries\n",
    "        articles.append(article)\n",
    "        \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Test Function</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = get_blog_articles(urls=urls)\n",
    "articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Bonus URL Scrape</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to hit Codeup's main blog page to scarpe the urls\n",
    "\n",
    "url = 'https://codeup.com/resources/#blog'\n",
    "headers = {'User-Agent': 'Codeup Bayes Data Science'} \n",
    "\n",
    "response = get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using class_ to get a list of tag elements from my soup object\n",
    "\n",
    "link_list = soup.find_all(class_=\"jet-listing-dynamic-link__link\")\n",
    "link_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(link_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty urls list and for each chunk above, grab the href/link\n",
    "# Add each link to the urls list\n",
    "\n",
    "urls = []\n",
    "for link in link_list:\n",
    "    urls.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow, 99 links! Ready to scrape titles and text from each\n",
    "\n",
    "print(len(urls))\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Bonus URL Function</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls():\n",
    "     '''\n",
    "    This function scrapes all of the Codeup blog urls from\n",
    "    the main Codeup blog page and returns a list of urls.\n",
    "    '''\n",
    "    # The main Codeup blog page with all the urls\n",
    "    url = 'https://codeup.com/resources/#blog'\n",
    "    \n",
    "    headers = {'User-Agent': 'Codeup Bayes Data Science'} \n",
    "    \n",
    "    # Send request to main page and get response\n",
    "    response = get(url, headers=headers)\n",
    "    \n",
    "    # Create soup object using response\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Create empty list to hold the urls for all blogs\n",
    "    urls = []\n",
    "    \n",
    "    # Create a list of the element tags that hold the href/links\n",
    "    link_list = soup.find_all(class_=\"jet-listing-dynamic-link__link\")\n",
    "    \n",
    "    # get the href/link from each element tag in my list\n",
    "    for link in link_list:\n",
    "        \n",
    "        # Add the link to my urls list\n",
    "        urls.append(link.get('href'))\n",
    "        \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I can use my same function with my new urls list!\n",
    "\n",
    "big_articles = acquire_blog_articles(urls=get_all_urls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(big_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color=blue>Inshorts News Articles</font>**\n",
    "\n",
    "**Goal:**  Write a function that scrapes the news articles for the following topics:\n",
    "\n",
    "- Business\n",
    "\n",
    "\n",
    "- Sports\n",
    "\n",
    "\n",
    "- Technology\n",
    "\n",
    "\n",
    "- Entertainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://inshorts.com/en/read/entertainment'\n",
    "\n",
    "response = get(url)\n",
    "response.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Scrape Article News Cards</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape a ResultSet of all the news cards on the page\n",
    "\n",
    "cards = soup.find_all(class_='news-card')\n",
    "print(type(cards))\n",
    "cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Scrape the Title from Each News Cards</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the title of each news card to a variable title\n",
    "for card in cards:\n",
    "    title = card.find('span', itemprop='headline' ).get_text()\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Scrape Author from News Cards</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the author of the news card to variable author\n",
    "for card in cards:\n",
    "    author = card.find('span', class_='author').get_text()\n",
    "    print(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Scrape Text from Article Page</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the text of each article to variable text\n",
    "\n",
    "for card in cards:\n",
    "    text = card.find('div', itemprop='articleBody').get_text()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Scrape Source URL from News Cards</font>**\n",
    "\n",
    "This broke when I used it with the sports articles, so I dumped it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the url of each news card to variable scource_url\n",
    "for card in cards:\n",
    "    source_url = card.find(class_='source').get('href')\n",
    "    print(source_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list, articles, to hold the dictionaries for each article\n",
    "articles = []\n",
    "\n",
    "# Loop through each news card on the page and get what we want\n",
    "for card in cards:\n",
    "    title = card.find('span', itemprop='headline' ).get_text()\n",
    "    author = card.find('span', class_='author').get_text()\n",
    "    content = card.find('div', itemprop='articleBody').get_text()\n",
    "    source = card.find(class_='source').get('href')\n",
    "    \n",
    "    # Create a dictionary, article, for each news card\n",
    "    article = {'title': title, 'author': author, 'content': content, 'source': source}\n",
    "    \n",
    "    # Add the dictionary, article, to our list of dictionaries, articles.\n",
    "    articles.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see our list contains 25 dictionaries for 25 news cards\n",
    "\n",
    "print(len(articles))\n",
    "articles[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color=purple>Build Article Function</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_articles():\n",
    "    '''\n",
    "    This function gets a list of urls from the main\n",
    "    page of the inshort card preview page.\n",
    "    '''\n",
    "    # Set base_url that will be used in get request\n",
    "    \n",
    "    base_url = 'https://inshorts.com/en/read/'\n",
    "    \n",
    "    topics = ['business', 'sports', 'technology', 'entertainment']\n",
    "    \n",
    "    # Create an empty list, articles, to hold our dictionaries\n",
    "    articles = []\n",
    "    \n",
    "    for topic in topics:\n",
    "    \n",
    "        # Get a response object from the main inshorts page\n",
    "        response = get(base_url + topic)\n",
    "\n",
    "        # Create soup object using response from inshort\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Scrape a ResultSet of all the news cards on the page\n",
    "        cards = soup.find_all(class_='news-card')\n",
    "\n",
    "        # Loop through each news card on the page and get what we want\n",
    "        for card in cards:\n",
    "            title = card.find('span', itemprop='headline' ).get_text()\n",
    "            author = card.find('span', class_='author').get_text()\n",
    "            content = card.find('div', itemprop='articleBody').get_text()\n",
    "\n",
    "            # Create a dictionary, article, for each news card\n",
    "            article = ({'topic': topic, \n",
    "                        'title': title, \n",
    "                        'author': author, \n",
    "                        'content': content})\n",
    "\n",
    "            # Add the dictionary, article, to our list of dictionaries, articles.\n",
    "            articles.append(article)\n",
    "            \n",
    "    # Why not return it as a DataFrame?!\n",
    "    return pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Delhi-Mumbai tickets to cost ₹3,500-₹10,000, a...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>The government has divided air routes into 7 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Govt releases fare structure for domestic flig...</td>\n",
       "      <td>Nandini Sinha</td>\n",
       "      <td>The DGCA has released fare structure for domes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Strides Pharma to conduct human trials for pot...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>Bengaluru-based Strides Pharma Science has rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Canada's inflation falls below zero for the fi...</td>\n",
       "      <td>Anushka Dixit</td>\n",
       "      <td>Canada's inflation turned negative and dropped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Fares to be capped, airlines can resume one-th...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>The Ministry of Civil Aviation on Thursday sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>False &amp; baseless: IMPPA on rumours of TV shoot...</td>\n",
       "      <td>Atul Mishra</td>\n",
       "      <td>Indian Motion Picture Producers' Association (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>I will take a pay cut if it helps the industry...</td>\n",
       "      <td>Udit Gupta</td>\n",
       "      <td>Kartik Aaryan during an interview with Anupama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Govt will consider plan on limited resumption ...</td>\n",
       "      <td>Atul Mishra</td>\n",
       "      <td>Maharashtra CM Uddhav Thackeray told the enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Baseless &amp; ridiculous: Peeyush on link-up rumo...</td>\n",
       "      <td>Udit Gupta</td>\n",
       "      <td>Media professional Peeyush Pandey has called t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Irrfan's son Babil shares old pics of actor me...</td>\n",
       "      <td>Udit Gupta</td>\n",
       "      <td>Late actor Irrfan Khan's son Babil Khan on Thu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic                                              title  \\\n",
       "0        business  Delhi-Mumbai tickets to cost ₹3,500-₹10,000, a...   \n",
       "1        business  Govt releases fare structure for domestic flig...   \n",
       "2        business  Strides Pharma to conduct human trials for pot...   \n",
       "3        business  Canada's inflation falls below zero for the fi...   \n",
       "4        business  Fares to be capped, airlines can resume one-th...   \n",
       "..            ...                                                ...   \n",
       "94  entertainment  False & baseless: IMPPA on rumours of TV shoot...   \n",
       "95  entertainment  I will take a pay cut if it helps the industry...   \n",
       "96  entertainment  Govt will consider plan on limited resumption ...   \n",
       "97  entertainment  Baseless & ridiculous: Peeyush on link-up rumo...   \n",
       "98  entertainment  Irrfan's son Babil shares old pics of actor me...   \n",
       "\n",
       "                    author                                            content  \n",
       "0   Krishna Veera Vanamali  The government has divided air routes into 7 c...  \n",
       "1            Nandini Sinha  The DGCA has released fare structure for domes...  \n",
       "2   Krishna Veera Vanamali  Bengaluru-based Strides Pharma Science has rec...  \n",
       "3            Anushka Dixit  Canada's inflation turned negative and dropped...  \n",
       "4   Krishna Veera Vanamali  The Ministry of Civil Aviation on Thursday sai...  \n",
       "..                     ...                                                ...  \n",
       "94             Atul Mishra  Indian Motion Picture Producers' Association (...  \n",
       "95              Udit Gupta  Kartik Aaryan during an interview with Anupama...  \n",
       "96             Atul Mishra  Maharashtra CM Uddhav Thackeray told the enter...  \n",
       "97              Udit Gupta  Media professional Peeyush Pandey has called t...  \n",
       "98              Udit Gupta  Late actor Irrfan Khan's son Babil Khan on Thu...  \n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_news_articles()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "200px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
