{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Beautiful-Soup---Web-Scraping\" data-toc-modified-id=\"Beautiful-Soup---Web-Scraping-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Beautiful Soup - Web Scraping</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-Beautiful-Soup?\" data-toc-modified-id=\"What-is-Beautiful-Soup?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><strong><font color=\"red\">What is Beautiful Soup?</font></strong></a></span></li><li><span><a href=\"#So-What-Do-I-Do-With-Beautiful-Soup?\" data-toc-modified-id=\"So-What-Do-I-Do-With-Beautiful-Soup?-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><strong><font color=\"orange\">So What Do I Do With Beautiful Soup?</font></strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#HTML-Components\" data-toc-modified-id=\"HTML-Components-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span><strong><font color=\"purple\">HTML Components</font></strong></a></span></li><li><span><a href=\"#HTML-Terms\" data-toc-modified-id=\"HTML-Terms-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span><strong><font color=\"purple\">HTML Terms</font></strong></a></span></li><li><span><a href=\"#HTML-Properties\" data-toc-modified-id=\"HTML-Properties-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span><strong><font color=\"purple\">HTML Properties</font></strong></a></span></li></ul></li><li><span><a href=\"#Now-What?\" data-toc-modified-id=\"Now-What?-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><strong><font color=\"green\">Now What?</font></strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Grab-Title-from-Page\" data-toc-modified-id=\"Grab-Title-from-Page-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Grab Title from Page</a></span></li><li><span><a href=\"#Grab-Text-from-Page\" data-toc-modified-id=\"Grab-Text-from-Page-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Grab Text from Page</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup - Web Scraping\n",
    "\n",
    "#### **<font color=red>What is Beautiful Soup?</font>**\n",
    "\n",
    "\n",
    "\n",
    "#### **<font color=orange>So What Do I Do With Beautiful Soup?</font>**\n",
    "\n",
    "Here, we are looking to retrieve content from a web page, but the web page is written in HTML (HyperText Markup Language), so we need a basic understanding of the different HTML elements used to create web pages.\n",
    "\n",
    "##### **<font color=purple>HTML Elements</font>**\n",
    "\n",
    "`<html>` tag identifies all contents as html\n",
    "\n",
    "`<head>` tag contains data about the title of the web page\n",
    "\n",
    "`<body>` tag contains the main content of the web page\n",
    "\n",
    "`<p>` or paragraph tag creates new pargraphs of text\n",
    "\n",
    "`<a>` tag (tell the browser to render a link). `<a>` tags use the `href` property to tell the link where to go.\n",
    "\n",
    "`<div>` tag indentifies a division of the page\n",
    "\n",
    "`<b>` tag bolds the text inside\n",
    "\n",
    "`<i>` tag italicizes the text inside\n",
    "\n",
    "`<table>` tag creates a table\n",
    "\n",
    "`<form>` tag creates an input form\n",
    "   \n",
    "><font color=purple>The tags are nested inside of the main html tag like you see below.</font>\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "    <p>\n",
    "        <a href = \"link\", id='name_of_link'>\n",
    "    </p>\n",
    "    <p class=''>\n",
    "    </p>\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "##### **<font color=purple>HTML Terms</font>**\n",
    "\n",
    "**child** -> a tag inside of another tag. The `<p>` tags above are children of the `<body>` tag.\n",
    "\n",
    "**parent** -> the tag another tag is inside of. The `<body>` tag is the parent of the `<p>` tag.\n",
    "\n",
    "**sibling** -> a tag that is nested inside the same parent tag as another tag. The two `<p>` tags are siblings tags inside of the `<body>` tag.\n",
    "\n",
    "##### **<font color=purple>HTML Properties</font>**\n",
    "\n",
    "These are optional, but they make the HTML elements easier to work with because they give the elements names. You will have to examine a web page to find out if it uses these properties.\n",
    "\n",
    "`class` is a property of an HTML element. One element can have multiple classes and elements can share the same classes, so classes cannot be used as unique identifiers.\n",
    "\n",
    "`id` is a property of an HTML element. Each element can only have one id, so they can be used as unique identifiers.\n",
    "\n",
    "#### **<font color=green>Now What?</font>**\n",
    "\n",
    "We will need to use the `requests` library to retrieve the HTML from a web page we want to scrape. You can review how to use the `requests` library in my notebook [here](https://faithkane3.github.io/time_series_review/time_series_review).\n",
    "\n",
    "Next, we will inspect the structure of the web page by right-clicking on the page we want to scrape and clicking 'inspect'. This will allow us to move our cursor over the part of the page we want to scrape and see the responsible HTML code for that section high-lighted on the right. We can use the tag and its properties with `BeautifulSoup` to `soup.find(name=tag)`\n",
    "\n",
    "We will need to use `BeautifulSoup` to parse the HTML response to our request. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {'User-Agent': 'Codeup Bayes Data Science'} \n",
    "    \n",
    "response = requests.get(url, headers=headers)\n",
    "response.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Here's our long string\n",
    "\n",
    "print(type(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "# We want to use response.content to make our Soup\n",
    "\n",
    "print(type(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "# Use BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Now we have our BeautifulSoup object, we can use its built-in methods and properties\n",
    "\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grab Title from Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup’s Data Science Career Accelerator is Here!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1', class_='jupiterx-post-title' ).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grab Text from Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.Data Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.Our program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.We focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.Applications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.If you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = soup.find('div', itemprop='text').get_text()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.Data Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.Our program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.We focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.Applications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.If you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = soup.find('div', class_='jupiterx-post-content').get_text()\n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
