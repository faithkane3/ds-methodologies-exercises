{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Natural-Language-Processing\" data-toc-modified-id=\"Natural-Language-Processing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Natural Language Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-Natural-Language-Processing?\" data-toc-modified-id=\"What-is-Natural-Language-Processing?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><strong><font color=\"red\">What is Natural Language Processing?</font></strong></a></span></li><li><span><a href=\"#So-What?\" data-toc-modified-id=\"So-What?-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><strong><font color=\"orange\">So What?</font></strong></a></span></li><li><span><a href=\"#Normalization-Examples:\" data-toc-modified-id=\"Normalization-Examples:-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><strong><font color=\"purple\">Normalization Examples:</font></strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Lowercase-Using-df.col.str.lower()\" data-toc-modified-id=\"Lowercase-Using-df.col.str.lower()-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span><strong>Lowercase Using <code>df.col.str.lower()</code></strong></a></span></li><li><span><a href=\"#Normalize-Unicode-Characters\" data-toc-modified-id=\"Normalize-Unicode-Characters-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span><strong>Normalize Unicode Characters</strong></a></span></li><li><span><a href=\"#Remove-Special-Characters-Using-Regex\" data-toc-modified-id=\"Remove-Special-Characters-Using-Regex-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span><strong>Remove Special Characters Using Regex</strong></a></span></li><li><span><a href=\"#Basic-Clean-Function\" data-toc-modified-id=\"Basic-Clean-Function-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Basic Clean Function</a></span></li></ul></li><li><span><a href=\"#Tokenization-Examples:\" data-toc-modified-id=\"Tokenization-Examples:-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><strong><font color=\"purple\">Tokenization Examples:</font></strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-.split()\" data-toc-modified-id=\"Using-.split()-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span><strong>Using <code>.split()</code></strong></a></span></li><li><span><a href=\"#Using-Regex\" data-toc-modified-id=\"Using-Regex-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Using Regex</a></span></li><li><span><a href=\"#Using-NLTK-Tokenization\" data-toc-modified-id=\"Using-NLTK-Tokenization-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Using NLTK Tokenization</a></span></li><li><span><a href=\"#Tokenize-Function\" data-toc-modified-id=\"Tokenize-Function-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span>Tokenize Function</a></span></li><li><span><a href=\"#Using-NLTK-PorterStemmer\" data-toc-modified-id=\"Using-NLTK-PorterStemmer-1.4.5\"><span class=\"toc-item-num\">1.4.5&nbsp;&nbsp;</span><strong>Using NLTK PorterStemmer</strong></a></span></li><li><span><a href=\"#Stem-Function\" data-toc-modified-id=\"Stem-Function-1.4.6\"><span class=\"toc-item-num\">1.4.6&nbsp;&nbsp;</span>Stem Function</a></span></li><li><span><a href=\"#Using-NLTK-WordNetLemmatizer\" data-toc-modified-id=\"Using-NLTK-WordNetLemmatizer-1.4.7\"><span class=\"toc-item-num\">1.4.7&nbsp;&nbsp;</span><strong>Using NLTK WordNetLemmatizer</strong></a></span></li><li><span><a href=\"#Lemmatize-Function\" data-toc-modified-id=\"Lemmatize-Function-1.4.8\"><span class=\"toc-item-num\">1.4.8&nbsp;&nbsp;</span>Lemmatize Function</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from acquire_walkthrough import get_all_urls, get_blog_articles, get_news_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "\n",
    "#### **<font color=red>What is Natural Language Processing?</font>**\n",
    "\n",
    "Natural Language Processing allows you to use techniques in Python libraries like NLTK (Natural Language Tool Kit) and Spacy to create machine-useable structure out of natural language text. In other words, you can manipulate natural language in such a way that renders it useful in machine learning. Machines can't read words, but they can recognize numbers, so we have to process the text we want to use in a way that retains the original meaning while representing the text with numbers.\n",
    "\n",
    "#### **<font color=orange>So What?</font>**\n",
    "\n",
    "We need to know some basic terminology to get started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization** - is when you perform a series of tasks like making all text lowercase, removing punctuation, expanding contractions, removing anything that's not an ASCII character, etc.\n",
    "\n",
    "#### **<font color=purple>Normalization Examples:</font>**\n",
    "\n",
    "##### **Lowercase Using `df.col.str.lower()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>RBI allows banks to offer moratorium on EMI pa...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>RBI Governor Shaktikanta Das on Friday announc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>GDP growth in 2020-21 expected to remain in ne...</td>\n",
       "      <td>Ankush Verma</td>\n",
       "      <td>Reserve Bank of India Governor Shaktikanta Das...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Govt releases fare structure for domestic flig...</td>\n",
       "      <td>Nandini Sinha</td>\n",
       "      <td>The DGCA has released fare structure for domes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Oxfam to fire 1,450 staff, shut offices in 18 ...</td>\n",
       "      <td>Anushka Dixit</td>\n",
       "      <td>Oxfam International has announced that it'll b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Vaccine development is like rollercoaster: Ser...</td>\n",
       "      <td>Dharna</td>\n",
       "      <td>Serum Institute of India CEO Adar Poonawalla s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title  \\\n",
       "0  business  RBI allows banks to offer moratorium on EMI pa...   \n",
       "1  business  GDP growth in 2020-21 expected to remain in ne...   \n",
       "2  business  Govt releases fare structure for domestic flig...   \n",
       "3  business  Oxfam to fire 1,450 staff, shut offices in 18 ...   \n",
       "4  business  Vaccine development is like rollercoaster: Ser...   \n",
       "\n",
       "                   author                                            content  \n",
       "0  Krishna Veera Vanamali  RBI Governor Shaktikanta Das on Friday announc...  \n",
       "1            Ankush Verma  Reserve Bank of India Governor Shaktikanta Das...  \n",
       "2           Nandini Sinha  The DGCA has released fare structure for domes...  \n",
       "3           Anushka Dixit  Oxfam International has announced that it'll b...  \n",
       "4                  Dharna  Serum Institute of India CEO Adar Poonawalla s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_news_articles()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note I have not reassigned this or changed the inplace argument to True yet; just a look.\n",
    "\n",
    "df.content.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Normalize Unicode Characters**\n",
    "\n",
    "[Here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.normalize.html) is the documentation for using `unicodedata.normalize()` on a Pandas Series.\n",
    "\n",
    "```python\n",
    "df.col.str.normalize(form, unistr)\n",
    "```\n",
    "\n",
    "```python\n",
    "df.col.str.encode('ascii', 'ignore')\n",
    "```\n",
    "\n",
    "```python\n",
    "df.col.str.decode('utf-8', 'ignore')\n",
    "```\n",
    "\n",
    "```python\n",
    "df.col.str.replace(r\"[^A-z0-9'\\s]\", '', regex=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, this is a look because it has not been reassigned or changed in place.\n",
    "\n",
    "df.content.str.normalize('NFKC').str.encode('ascii', 'ignore').str.decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Remove Special Characters Using Regex**\n",
    "\n",
    "I found [this article](https://kanoki.org/2019/11/12/how-to-use-regex-in-pandas/) very helpful when using Regex in Pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, this is a look because it has not been reassigned or changed in place.\n",
    "\n",
    "df.content.str.replace(r\"[^A-z0-9'\\s]\", '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I can chain these together and reassign to my df as a new columm\n",
    "\n",
    "df['basic_clean'] = df.content.str.lower()\\\n",
    "                    .str.replace(r\"[^A-z0-9'\\s]\", '', regex=True)\\\n",
    "                    .str.normalize('NFKC')\\\n",
    "                    .str.encode('ascii', 'ignore')\\\n",
    "                    .str.decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Clean Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(df, col):\n",
    "    df['basic_clean'] = df[col].str.lower()\\\n",
    "                    .str.replace(r\"[^A-z0-9'\\s]\", '', regex=True)\\\n",
    "                    .str.normalize('NFKC')\\\n",
    "                    .str.encode('ascii', 'ignore')\\\n",
    "                    .str.decode('utf-8', 'ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>basic_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>RBI allows banks to offer moratorium on EMI pa...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>RBI Governor Shaktikanta Das on Friday announc...</td>\n",
       "      <td>rbi governor shaktikanta das on friday announc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>GDP growth in 2020-21 expected to remain in ne...</td>\n",
       "      <td>Ankush Verma</td>\n",
       "      <td>Reserve Bank of India Governor Shaktikanta Das...</td>\n",
       "      <td>reserve bank of india governor shaktikanta das...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title  \\\n",
       "0  business  RBI allows banks to offer moratorium on EMI pa...   \n",
       "1  business  GDP growth in 2020-21 expected to remain in ne...   \n",
       "\n",
       "                   author                                            content  \\\n",
       "0  Krishna Veera Vanamali  RBI Governor Shaktikanta Das on Friday announc...   \n",
       "1            Ankush Verma  Reserve Bank of India Governor Shaktikanta Das...   \n",
       "\n",
       "                                         basic_clean  \n",
       "0  rbi governor shaktikanta das on friday announc...  \n",
       "1  reserve bank of india governor shaktikanta das...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = basic_clean(df, 'content')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization** - is when you split larger strings of text into smaller pieces or tokens by setting a boundary. You might chunk a sentence into words using a space as a boundary or a paragraph into sentences using punctuation as a boundary.\n",
    "\n",
    "#### **<font color=purple>Tokenization Examples:</font>**\n",
    "\n",
    "##### **Using `.split()`**\n",
    "\n",
    "Tokenizing using `.split()` is simple but also limited to one delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Knowledge is the compound interest of curiosity. - James Clear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"There\\'s the kind of person who is always the victim in any story they tell. Always on the receiving end of some injustice. There\\'s the kind of person who is always the kind of hero of every story they tell. There\\'s the smart person; they delivered the clever put down there.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Regex\n",
    "\n",
    "**<font color=purple>Identifiers</font>**\n",
    "\n",
    "<table ><tr><th>Character</th><th>Description</th><th>Example Pattern Code</th><th >Exammple Match</th></tr>\n",
    "\n",
    "<tr ><td><span >\\d</span></td><td>A digit</td><td>file_\\d\\d</td><td>file_25</td></tr>\n",
    "\n",
    "<tr ><td><span >\\w</span></td><td>Alphanumeric</td><td>\\w-\\w\\w\\w</td><td>A-b_1</td></tr>\n",
    "\n",
    "\n",
    "\n",
    "<tr ><td><span >\\s</span></td><td>White space</td><td>a\\sb\\sc</td><td>a b c</td></tr>\n",
    "\n",
    "\n",
    "\n",
    "<tr ><td><span >\\D</span></td><td>A non digit</td><td>\\D\\D\\D</td><td>ABC</td></tr>\n",
    "\n",
    "<tr ><td><span >\\W</span></td><td>Non-alphanumeric</td><td>\\W\\W\\W\\W\\W</td><td>*-+=)</td></tr>\n",
    "\n",
    "<tr ><td><span >\\S</span></td><td>Non-whitespace</td><td>\\S\\S\\S\\S</td><td>Yoyo</td></tr></table>\n",
    "\n",
    "**<font color=purple>Quantifiers</font>**\n",
    "\n",
    "<table ><tr><th>Character</th><th>Description</th><th>Example Pattern Code</th><th >Exammple Match</th></tr>\n",
    "\n",
    "<tr ><td><span >+</span></td><td>Occurs one or more times</td><td>\tVersion \\w-\\w+</td><td>Version A-b1_1</td></tr>\n",
    "\n",
    "<tr ><td><span >{3}</span></td><td>Occurs exactly 3 times</td><td>\\D{3}</td><td>abc</td></tr>\n",
    "\n",
    "\n",
    "\n",
    "<tr ><td><span >{2,4}</span></td><td>Occurs 2 to 4 times</td><td>\\d{2,4}</td><td>123</td></tr>\n",
    "\n",
    "\n",
    "\n",
    "<tr ><td><span >{3,}</span></td><td>Occurs 3 or more</td><td>\\w{3,}</td><td>anycharacters</td></tr>\n",
    "\n",
    "<tr ><td><span >\\*</span></td><td>Occurs zero or more times</td><td>A\\*B\\*C*</td><td>AAACC</td></tr>\n",
    "\n",
    "<tr ><td><span >?</span></td><td>Once or none</td><td>plurals?</td><td>plural</td></tr></table>\n",
    "\n",
    "**<font color=purple>More Regex</font>**\n",
    "\n",
    "<table ><tr><th>Character</th><th>Description</th><th>Example</th></tr>\n",
    "    \n",
    "<tr ><td><span >|</span></td><td>or statement</td><td>r'dog|cat'</td></tr>\n",
    "\n",
    "<tr ><td><span >*</span></td><td>wildcard</td><td>r'.at'</td></tr>\n",
    "    \n",
    "<tr ><td><span >^</span></td><td>starts with</td><td>r'^\\d'</td></tr>\n",
    "    \n",
    "<tr ><td><span >[^]</span></td><td>exclusion</td><td>r'[^a-z]'</td></tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split your text using a regex pattern in .findall()\n",
    "\n",
    "pattern = r'[\\w]+'\n",
    "text = 'Knowledge is the compound interest of curiosity. - James Clear'\n",
    "\n",
    "tokens = re.findall(pattern, text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `.compile()` with .split(text) to split your text on more than one delimiter\n",
    "\n",
    "pattern = re.compile(r'[.;!?]')\n",
    "text = \"\"\"There's the kind of person who is always the victim in any story they tell. Always on the receiving end of some injustice. There's the kind of person who is always the kind of hero of every story they tell. There's the smart person; they delivered the clever put down there.\"\"\"\n",
    "\n",
    "pattern.split(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using NLTK Tokenization\n",
    "\n",
    "```python\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "df.col.apply(tokenizer.tokenize).str.join(' ')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.basic_clean.apply(tokenizer.tokenize)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we apply nltk's tokenizer to each row, or text, in our basic_clean Series\n",
    "\n",
    "df['clean_tokes'] = df.basic_clean.apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df, col):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    df['clean_tokes'] = df[col].apply(tokenizer.tokenize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>basic_clean</th>\n",
       "      <th>clean_tokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>RBI allows banks to offer moratorium on EMI pa...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>RBI Governor Shaktikanta Das on Friday announc...</td>\n",
       "      <td>rbi governor shaktikanta das on friday announc...</td>\n",
       "      <td>[rbi, governor, shaktikanta, das, on, friday, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>GDP growth in 2020-21 expected to remain in ne...</td>\n",
       "      <td>Ankush Verma</td>\n",
       "      <td>Reserve Bank of India Governor Shaktikanta Das...</td>\n",
       "      <td>reserve bank of india governor shaktikanta das...</td>\n",
       "      <td>[reserve, bank, of, india, governor, shaktikan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title  \\\n",
       "0  business  RBI allows banks to offer moratorium on EMI pa...   \n",
       "1  business  GDP growth in 2020-21 expected to remain in ne...   \n",
       "\n",
       "                   author                                            content  \\\n",
       "0  Krishna Veera Vanamali  RBI Governor Shaktikanta Das on Friday announc...   \n",
       "1            Ankush Verma  Reserve Bank of India Governor Shaktikanta Das...   \n",
       "\n",
       "                                         basic_clean  \\\n",
       "0  rbi governor shaktikanta das on friday announc...   \n",
       "1  reserve bank of india governor shaktikanta das...   \n",
       "\n",
       "                                         clean_tokes  \n",
       "0  [rbi, governor, shaktikanta, das, on, friday, ...  \n",
       "1  [reserve, bank, of, india, governor, shaktikan...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tokenize(df, 'basic_clean')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Using NLTK PorterStemmer**\n",
    "\n",
    "```python\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "```\n",
    "\n",
    "```python\n",
    "df.col.apply(lambda row: [ps.stem(word) for word in row])\n",
    "```\n",
    "\n",
    "```python\n",
    "df['stemmed'] = stems.str.join(' ')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.stem.porter.PorterStemmer"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.stem('turning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series of lists of stemmed words using our cleaned tokens\n",
    "\n",
    "stems = df.clean_tokes.apply(lambda row: [ps.stem(word) for word in row])\n",
    "stems.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join our cleaned, stemmed lists of words back into strings of words/tokens\n",
    "\n",
    "df['stemmed'] = stems.str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 300\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stem Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(df, col):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # Create porter stemmer\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Create a Series of lists of stemmed words using our cleaned tokens\n",
    "    stems = df[col].apply(lambda row: [ps.stem(word) for word in row])\n",
    "    \n",
    "    # Join our cleaned, stemmed lists of words back into strings of words/tokens\n",
    "    df['stemmed'] = stems.str.join(' ')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>basic_clean</th>\n",
       "      <th>clean_tokes</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>RBI allows banks to offer moratorium on EMI pa...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>RBI Governor Shaktikanta Das on Friday announc...</td>\n",
       "      <td>rbi governor shaktikanta das on friday announc...</td>\n",
       "      <td>[rbi, governor, shaktikanta, das, on, friday, ...</td>\n",
       "      <td>rbi governor shaktikanta da on friday announc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>GDP growth in 2020-21 expected to remain in ne...</td>\n",
       "      <td>Ankush Verma</td>\n",
       "      <td>Reserve Bank of India Governor Shaktikanta Das...</td>\n",
       "      <td>reserve bank of india governor shaktikanta das...</td>\n",
       "      <td>[reserve, bank, of, india, governor, shaktikan...</td>\n",
       "      <td>reserv bank of india governor shaktikanta da h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Govt releases fare structure for domestic flig...</td>\n",
       "      <td>Nandini Sinha</td>\n",
       "      <td>The DGCA has released fare structure for domes...</td>\n",
       "      <td>the dgca has released fare structure for domes...</td>\n",
       "      <td>[the, dgca, has, released, fare, structure, fo...</td>\n",
       "      <td>the dgca ha releas fare structur for domest fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Oxfam to fire 1,450 staff, shut offices in 18 ...</td>\n",
       "      <td>Anushka Dixit</td>\n",
       "      <td>Oxfam International has announced that it'll b...</td>\n",
       "      <td>oxfam international has announced that it'll b...</td>\n",
       "      <td>[oxfam, international, has, announced, that, i...</td>\n",
       "      <td>oxfam intern ha announc that it ' ll be fire 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Vaccine development is like rollercoaster: Ser...</td>\n",
       "      <td>Dharna</td>\n",
       "      <td>Serum Institute of India CEO Adar Poonawalla s...</td>\n",
       "      <td>serum institute of india ceo adar poonawalla s...</td>\n",
       "      <td>[serum, institute, of, india, ceo, adar, poona...</td>\n",
       "      <td>serum institut of india ceo adar poonawalla sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title  \\\n",
       "0  business  RBI allows banks to offer moratorium on EMI pa...   \n",
       "1  business  GDP growth in 2020-21 expected to remain in ne...   \n",
       "2  business  Govt releases fare structure for domestic flig...   \n",
       "3  business  Oxfam to fire 1,450 staff, shut offices in 18 ...   \n",
       "4  business  Vaccine development is like rollercoaster: Ser...   \n",
       "\n",
       "                   author                                            content  \\\n",
       "0  Krishna Veera Vanamali  RBI Governor Shaktikanta Das on Friday announc...   \n",
       "1            Ankush Verma  Reserve Bank of India Governor Shaktikanta Das...   \n",
       "2           Nandini Sinha  The DGCA has released fare structure for domes...   \n",
       "3           Anushka Dixit  Oxfam International has announced that it'll b...   \n",
       "4                  Dharna  Serum Institute of India CEO Adar Poonawalla s...   \n",
       "\n",
       "                                         basic_clean  \\\n",
       "0  rbi governor shaktikanta das on friday announc...   \n",
       "1  reserve bank of india governor shaktikanta das...   \n",
       "2  the dgca has released fare structure for domes...   \n",
       "3  oxfam international has announced that it'll b...   \n",
       "4  serum institute of india ceo adar poonawalla s...   \n",
       "\n",
       "                                         clean_tokes  \\\n",
       "0  [rbi, governor, shaktikanta, das, on, friday, ...   \n",
       "1  [reserve, bank, of, india, governor, shaktikan...   \n",
       "2  [the, dgca, has, released, fare, structure, fo...   \n",
       "3  [oxfam, international, has, announced, that, i...   \n",
       "4  [serum, institute, of, india, ceo, adar, poona...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  rbi governor shaktikanta da on friday announc ...  \n",
       "1  reserv bank of india governor shaktikanta da h...  \n",
       "2  the dgca ha releas fare structur for domest fl...  \n",
       "3  oxfam intern ha announc that it ' ll be fire 1...  \n",
       "4  serum institut of india ceo adar poonawalla sa...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = stem(df, 'clean_tokes')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Using NLTK WordNetLemmatizer**\n",
    "\n",
    "```python\n",
    "nltk.download('wordnet')\n",
    "```\n",
    "\n",
    "```python\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "```\n",
    "\n",
    "```python\n",
    "lemmas = df.col.apply(lambda row: [wnl.lemmatize(word) for word in row])\n",
    "```\n",
    "\n",
    "```python\n",
    "df['lemmatized'] = lemmas.str.join(' ')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = df.clean_tokes.apply(lambda row: [wnl.lemmatize(word) for word in row])\n",
    "lemmas.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join our cleaned, lemmatized lists of words back into strings of words/tokens\n",
    "\n",
    "df['lemmatized'] = lemmas.str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(df, col):\n",
    "    '''\n",
    "    This function takes in a df and a string for column name and\n",
    "    returns a the original df with a new column called 'lemmatized'.\n",
    "    '''\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = df[col].apply(lambda row: [wnl.lemmatize(word) for word in row])\n",
    "    df['lemmatized'] = lemmas.str.join(' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>basic_clean</th>\n",
       "      <th>clean_tokes</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>RBI allows banks to offer moratorium on EMI pa...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>RBI Governor Shaktikanta Das on Friday announc...</td>\n",
       "      <td>rbi governor shaktikanta das on friday announc...</td>\n",
       "      <td>[rbi, governor, shaktikanta, das, on, friday, ...</td>\n",
       "      <td>rbi governor shaktikanta da on friday announc ...</td>\n",
       "      <td>rbi governor shaktikanta da on friday announce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>GDP growth in 2020-21 expected to remain in ne...</td>\n",
       "      <td>Ankush Verma</td>\n",
       "      <td>Reserve Bank of India Governor Shaktikanta Das...</td>\n",
       "      <td>reserve bank of india governor shaktikanta das...</td>\n",
       "      <td>[reserve, bank, of, india, governor, shaktikan...</td>\n",
       "      <td>reserv bank of india governor shaktikanta da h...</td>\n",
       "      <td>reserve bank of india governor shaktikanta da ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Govt releases fare structure for domestic flig...</td>\n",
       "      <td>Nandini Sinha</td>\n",
       "      <td>The DGCA has released fare structure for domes...</td>\n",
       "      <td>the dgca has released fare structure for domes...</td>\n",
       "      <td>[the, dgca, has, released, fare, structure, fo...</td>\n",
       "      <td>the dgca ha releas fare structur for domest fl...</td>\n",
       "      <td>the dgca ha released fare structure for domest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Oxfam to fire 1,450 staff, shut offices in 18 ...</td>\n",
       "      <td>Anushka Dixit</td>\n",
       "      <td>Oxfam International has announced that it'll b...</td>\n",
       "      <td>oxfam international has announced that it'll b...</td>\n",
       "      <td>[oxfam, international, has, announced, that, i...</td>\n",
       "      <td>oxfam intern ha announc that it ' ll be fire 1...</td>\n",
       "      <td>oxfam international ha announced that it ' ll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Vaccine development is like rollercoaster: Ser...</td>\n",
       "      <td>Dharna</td>\n",
       "      <td>Serum Institute of India CEO Adar Poonawalla s...</td>\n",
       "      <td>serum institute of india ceo adar poonawalla s...</td>\n",
       "      <td>[serum, institute, of, india, ceo, adar, poona...</td>\n",
       "      <td>serum institut of india ceo adar poonawalla sa...</td>\n",
       "      <td>serum institute of india ceo adar poonawalla s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title  \\\n",
       "0  business  RBI allows banks to offer moratorium on EMI pa...   \n",
       "1  business  GDP growth in 2020-21 expected to remain in ne...   \n",
       "2  business  Govt releases fare structure for domestic flig...   \n",
       "3  business  Oxfam to fire 1,450 staff, shut offices in 18 ...   \n",
       "4  business  Vaccine development is like rollercoaster: Ser...   \n",
       "\n",
       "                   author                                            content  \\\n",
       "0  Krishna Veera Vanamali  RBI Governor Shaktikanta Das on Friday announc...   \n",
       "1            Ankush Verma  Reserve Bank of India Governor Shaktikanta Das...   \n",
       "2           Nandini Sinha  The DGCA has released fare structure for domes...   \n",
       "3           Anushka Dixit  Oxfam International has announced that it'll b...   \n",
       "4                  Dharna  Serum Institute of India CEO Adar Poonawalla s...   \n",
       "\n",
       "                                         basic_clean  \\\n",
       "0  rbi governor shaktikanta das on friday announc...   \n",
       "1  reserve bank of india governor shaktikanta das...   \n",
       "2  the dgca has released fare structure for domes...   \n",
       "3  oxfam international has announced that it'll b...   \n",
       "4  serum institute of india ceo adar poonawalla s...   \n",
       "\n",
       "                                         clean_tokes  \\\n",
       "0  [rbi, governor, shaktikanta, das, on, friday, ...   \n",
       "1  [reserve, bank, of, india, governor, shaktikan...   \n",
       "2  [the, dgca, has, released, fare, structure, fo...   \n",
       "3  [oxfam, international, has, announced, that, i...   \n",
       "4  [serum, institute, of, india, ceo, adar, poona...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  rbi governor shaktikanta da on friday announc ...   \n",
       "1  reserv bank of india governor shaktikanta da h...   \n",
       "2  the dgca ha releas fare structur for domest fl...   \n",
       "3  oxfam intern ha announc that it ' ll be fire 1...   \n",
       "4  serum institut of india ceo adar poonawalla sa...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  rbi governor shaktikanta da on friday announce...  \n",
       "1  reserve bank of india governor shaktikanta da ...  \n",
       "2  the dgca ha released fare structure for domest...  \n",
       "3  oxfam international ha announced that it ' ll ...  \n",
       "4  serum institute of india ceo adar poonawalla s...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = lemmatize(df, 'clean_tokes')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
