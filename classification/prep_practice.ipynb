{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import acquire\n",
    "import util\n",
    "import pandas_profiling\n",
    "import prepare\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Columns:\n",
    "\n",
    "    -I'm going to drop \"deck\" because it only has 203 columns out of 891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"deck\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fillna:\n",
    "\n",
    "    -Do a consistent fill of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split:\n",
    "\n",
    "    -Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, train_size=.8, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute:\n",
    "\n",
    "    -fill the NANs with the mode value in embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -fit and transform train \n",
    "    \n",
    "    -transform test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mode.fit(train[[\"embarked\"]])\n",
    "train[\"embarked\"] = imp_mode.transform(train[[\"embarked\"]])\n",
    "test[\"embarked\"] = imp_mode.transform(test[[\"embarked\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    129\n",
       "C     40\n",
       "Q     10\n",
       "Name: embarked, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.embarked.value_counts()\n",
    "test.embarked.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -fill the NANs with the median value in age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_median = SimpleImputer(missing_values=np.nan, strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"age\"] = imp_median.fit_transform(train[[\"age\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -check to make sure there are no more NULL values in the age column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.age.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding:\n",
    "\n",
    "    -Integer Encoding\n",
    "    \n",
    "    -One hot encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -create encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -fit to train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_encoder.fit(train.embarked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -transform the \"embarked\" column data from letters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.embarked = int_encoder.transform(train.embarked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -check the counts of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    517\n",
       "0    128\n",
       "1     67\n",
       "Name: embarked, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.embarked.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -transform \"embarked\" into a np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_array = np.array(train.embarked)\n",
    "embarked_array[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -transform \"embarked\" into a 2D array to feed to OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_array = embarked_array.reshape(len(embarked_array),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -create OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, categories=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -fit and transform to embarked_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_ohe = ohe.fit_transform(embarked_array)\n",
    "embarked_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test.embarked = int_encoder.transform(test.embarked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -transform test.embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_array = np.array(test.embarked).reshape(len(test.embarked), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -transform embarked_array with OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_test_ohe = ohe.transform(embarked_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_test_ohe[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare.prep_iris(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     passenger_id  survived  pclass     sex       age  sibsp  parch      fare  \\\n",
       " 0               0         0       3    male  0.271174      1      0  0.014151   \n",
       " 1               1         1       1  female  0.472229      1      0  0.139136   \n",
       " 2               2         1       3  female  0.321438      0      0  0.015469   \n",
       " 3               3         1       1  female  0.434531      1      0  0.103644   \n",
       " 4               4         0       3    male  0.434531      0      0  0.015713   \n",
       " 5               5         0       3    male       NaN      0      0  0.016510   \n",
       " 6               6         0       1    male  0.673285      0      0  0.101229   \n",
       " 7               7         0       3    male  0.019854      3      1  0.041136   \n",
       " 8               8         1       3  female  0.334004      0      2  0.021731   \n",
       " 9               9         1       2  female  0.170646      1      0  0.058694   \n",
       " 10             10         1       3  female  0.044986      1      1  0.032596   \n",
       " 11             11         1       1  female  0.723549      0      0  0.051822   \n",
       " 12             12         0       3    male  0.246042      0      0  0.015713   \n",
       " 13             13         0       3    male  0.484795      1      5  0.061045   \n",
       " 14             14         0       3  female  0.170646      0      0  0.015330   \n",
       " 15             15         1       2  female  0.685851      0      0  0.031230   \n",
       " 16             16         0       3    male  0.019854      4      1  0.056848   \n",
       " 17             17         1       2    male       NaN      0      0  0.025374   \n",
       " 18             18         0       3  female  0.384267      1      0  0.035134   \n",
       " 19             19         1       3  female       NaN      0      0  0.014102   \n",
       " 20             20         0       2    male  0.434531      0      0  0.050749   \n",
       " 21             21         1       2    male  0.421965      0      0  0.025374   \n",
       " 22             22         1       3  female  0.183212      0      0  0.015672   \n",
       " 23             23         1       1    male  0.346569      0      0  0.069291   \n",
       " 24             24         0       3  female  0.095250      3      1  0.041136   \n",
       " 25             25         1       3  female  0.472229      1      5  0.061264   \n",
       " 26             26         0       3    male       NaN      0      0  0.014102   \n",
       " 27             27         0       1    male  0.233476      3      2  0.513342   \n",
       " 28             28         1       3  female       NaN      0      0  0.015379   \n",
       " 29             29         0       3    male       NaN      0      0  0.015412   \n",
       " ..            ...       ...     ...     ...       ...    ...    ...       ...   \n",
       " 861           861         0       2    male  0.258608      1      0  0.022447   \n",
       " 862           862         1       1  female  0.597889      0      0  0.050610   \n",
       " 863           863         0       3  female       NaN      8      2  0.135753   \n",
       " 864           864         0       2    male  0.296306      0      0  0.025374   \n",
       " 865           865         1       2  female  0.522493      0      0  0.025374   \n",
       " 866           866         1       2  female  0.334004      1      0  0.027050   \n",
       " 867           867         0       1    male  0.384267      0      0  0.098561   \n",
       " 868           868         0       3    male       NaN      0      0  0.018543   \n",
       " 869           869         1       3    male  0.044986      1      1  0.021731   \n",
       " 870           870         0       3    male  0.321438      0      0  0.015412   \n",
       " 871           871         1       1  female  0.585323      1      1  0.102579   \n",
       " 872           872         0       1    male  0.409399      0      0  0.009759   \n",
       " 873           873         0       3    male  0.585323      0      0  0.017567   \n",
       " 874           874         1       2  female  0.346569      1      0  0.046845   \n",
       " 875           875         1       3  female  0.183212      0      0  0.014102   \n",
       " 876           876         0       3    male  0.246042      0      0  0.019218   \n",
       " 877           877         0       3    male  0.233476      0      0  0.015412   \n",
       " 878           878         0       3    male       NaN      0      0  0.015412   \n",
       " 879           879         1       1  female  0.698417      0      1  0.162314   \n",
       " 880           880         1       2  female  0.308872      0      1  0.050749   \n",
       " 881           881         0       3    male  0.409399      0      0  0.015412   \n",
       " 882           882         0       3  female  0.271174      0      0  0.020527   \n",
       " 883           883         0       2    male  0.346569      0      0  0.020495   \n",
       " 884           884         0       3    male  0.308872      0      0  0.013761   \n",
       " 885           885         0       3  female  0.484795      0      5  0.056848   \n",
       " 886           886         0       2    male  0.334004      0      0  0.025374   \n",
       " 887           887         1       1  female  0.233476      0      0  0.058556   \n",
       " 888           888         0       3  female       NaN      1      2  0.045771   \n",
       " 889           889         1       1    male  0.321438      0      0  0.058556   \n",
       " 890           890         0       3    male  0.396833      0      0  0.015127   \n",
       " \n",
       "      embarked   class  embark_town  alone  \n",
       " 0           2   Third  Southampton      0  \n",
       " 1           0   First    Cherbourg      0  \n",
       " 2           2   Third  Southampton      1  \n",
       " 3           2   First  Southampton      0  \n",
       " 4           2   Third  Southampton      1  \n",
       " 5           1   Third   Queenstown      1  \n",
       " 6           2   First  Southampton      1  \n",
       " 7           2   Third  Southampton      0  \n",
       " 8           2   Third  Southampton      0  \n",
       " 9           0  Second    Cherbourg      0  \n",
       " 10          2   Third  Southampton      0  \n",
       " 11          2   First  Southampton      1  \n",
       " 12          2   Third  Southampton      1  \n",
       " 13          2   Third  Southampton      0  \n",
       " 14          2   Third  Southampton      1  \n",
       " 15          2  Second  Southampton      1  \n",
       " 16          1   Third   Queenstown      0  \n",
       " 17          2  Second  Southampton      1  \n",
       " 18          2   Third  Southampton      0  \n",
       " 19          0   Third    Cherbourg      1  \n",
       " 20          2  Second  Southampton      1  \n",
       " 21          2  Second  Southampton      1  \n",
       " 22          1   Third   Queenstown      1  \n",
       " 23          2   First  Southampton      1  \n",
       " 24          2   Third  Southampton      0  \n",
       " 25          2   Third  Southampton      0  \n",
       " 26          0   Third    Cherbourg      1  \n",
       " 27          2   First  Southampton      0  \n",
       " 28          1   Third   Queenstown      1  \n",
       " 29          2   Third  Southampton      1  \n",
       " ..        ...     ...          ...    ...  \n",
       " 861         2  Second  Southampton      0  \n",
       " 862         2   First  Southampton      1  \n",
       " 863         2   Third  Southampton      0  \n",
       " 864         2  Second  Southampton      1  \n",
       " 865         2  Second  Southampton      1  \n",
       " 866         0  Second    Cherbourg      0  \n",
       " 867         2   First  Southampton      1  \n",
       " 868         2   Third  Southampton      1  \n",
       " 869         2   Third  Southampton      0  \n",
       " 870         2   Third  Southampton      1  \n",
       " 871         2   First  Southampton      0  \n",
       " 872         2   First  Southampton      1  \n",
       " 873         2   Third  Southampton      1  \n",
       " 874         0  Second    Cherbourg      0  \n",
       " 875         0   Third    Cherbourg      1  \n",
       " 876         2   Third  Southampton      1  \n",
       " 877         2   Third  Southampton      1  \n",
       " 878         2   Third  Southampton      1  \n",
       " 879         0   First    Cherbourg      0  \n",
       " 880         2  Second  Southampton      0  \n",
       " 881         2   Third  Southampton      1  \n",
       " 882         2   Third  Southampton      1  \n",
       " 883         2  Second  Southampton      1  \n",
       " 884         2   Third  Southampton      1  \n",
       " 885         1   Third   Queenstown      0  \n",
       " 886         2  Second  Southampton      1  \n",
       " 887         2   First  Southampton      1  \n",
       " 888         2   Third  Southampton      0  \n",
       " 889         0   First    Cherbourg      1  \n",
       " 890         1   Third   Queenstown      1  \n",
       " \n",
       " [889 rows x 12 columns], LabelEncoder())"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare.prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "passenger_id    891 non-null int64\n",
      "survived        891 non-null int64\n",
      "pclass          891 non-null int64\n",
      "sex             891 non-null object\n",
      "age             714 non-null float64\n",
      "sibsp           891 non-null int64\n",
      "parch           891 non-null int64\n",
      "fare            891 non-null float64\n",
      "embarked        889 non-null object\n",
      "class           891 non-null object\n",
      "embark_town     889 non-null object\n",
      "alone           891 non-null int64\n",
      "dtypes: float64(2), int64(6), object(4)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN      177\n",
       "24.00     30\n",
       "22.00     27\n",
       "18.00     26\n",
       "28.00     25\n",
       "19.00     25\n",
       "30.00     25\n",
       "21.00     24\n",
       "25.00     23\n",
       "36.00     22\n",
       "29.00     20\n",
       "32.00     18\n",
       "26.00     18\n",
       "35.00     18\n",
       "27.00     18\n",
       "16.00     17\n",
       "31.00     17\n",
       "34.00     15\n",
       "23.00     15\n",
       "33.00     15\n",
       "20.00     15\n",
       "39.00     14\n",
       "17.00     13\n",
       "42.00     13\n",
       "40.00     13\n",
       "45.00     12\n",
       "38.00     11\n",
       "50.00     10\n",
       "2.00      10\n",
       "4.00      10\n",
       "        ... \n",
       "28.50      2\n",
       "63.00      2\n",
       "0.83       2\n",
       "30.50      2\n",
       "70.00      2\n",
       "57.00      2\n",
       "0.75       2\n",
       "13.00      2\n",
       "59.00      2\n",
       "10.00      2\n",
       "64.00      2\n",
       "40.50      2\n",
       "45.50      2\n",
       "32.50      2\n",
       "20.50      1\n",
       "24.50      1\n",
       "0.67       1\n",
       "70.50      1\n",
       "0.92       1\n",
       "74.00      1\n",
       "34.50      1\n",
       "14.50      1\n",
       "80.00      1\n",
       "12.00      1\n",
       "53.00      1\n",
       "36.50      1\n",
       "55.50      1\n",
       "66.00      1\n",
       "23.50      1\n",
       "0.42       1\n",
       "Name: age, Length: 89, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.age.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
