{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "- No labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clustering is an unsupervised machine learning methodology for grouping and identifing similar objects, people, or observations.\n",
    "\n",
    "    \n",
    "    - We can create a new feature (or predictor) from this using these cluster ids, and use it in your ML or as a target.\n",
    "\n",
    "\n",
    "- Clustering is often used as a preprocessing or an exploratory step in the data science pipeline so that the cluster that each item is assigned to becomes a feature for a supervised model.\n",
    "\n",
    "\n",
    "- In this module, you will be introduced to various clustering algorithms and learn why and when to use them. You will learn how to use clustering methods to identify similar groups using Python using Scikit-Learn. You will learn how apply these clusters further down the pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cases\n",
    "\n",
    "- Text: Document classification, summarization, topic modeling, recommendations\n",
    "\n",
    "\n",
    "- Geographic: crime zones, housing prices\n",
    "\n",
    "\n",
    "- Marketing: Customer segmentation, market research\n",
    "\n",
    "\n",
    "- Anomaly detection: account takeover, security risk, fraud\n",
    "\n",
    "\n",
    "- Image processing: radiology, security\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "\n",
    "\n",
    "- Euclidean Distance\n",
    "\n",
    "\n",
    "- Manhattan Distance\n",
    "\n",
    "\n",
    "- Cosine Similarity\n",
    "\n",
    "\n",
    "- Sparse vs. Dense Matrix\n",
    "\n",
    "\n",
    "- Manhattan (Taxicab) vs Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "\n",
    "- Input: continuous data, or ordered discrete data at a minimum.\n",
    "\n",
    "\n",
    "- Output: Integer representing a cluster id.\n",
    "\n",
    "\n",
    "    - The number itself doesn't mean anything except that those who share the same number are most similar. In addition, the number doesn't compare to any of the other cluster id's beyond the fact that they are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Clustering Agorithms\n",
    "\n",
    "### K-Means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Description\n",
    "\n",
    "\n",
    "    - most popular \"clustering\" algorithms.\n",
    "\n",
    "\n",
    "    - stores k centroids that it uses to define clusters.\n",
    "\n",
    "\n",
    "    - A point is considered to be in a particular cluster if it is closer to that cluster's centroid than any other centroid.\n",
    "    \n",
    "    \n",
    "    - K-Means finds the best centroids by alternating between (1) assigning data points to clusters based on the current centroids (2) chosing centroids (points which are the center of a cluster) based on the current assignment of data points to clusters.\n",
    "    \n",
    "    \n",
    "    - Python implementation: sklearn.cluster.KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PARAMETERS\n",
    "\n",
    "\n",
    "- Number of clusters (k): The number of clusters to form, which is equal to the number of centroids to generate\n",
    "\n",
    "\n",
    "- Number of initializations (n_init): The number of times the algorithm will 'begin', i.e. kick off with different centroid seeds\n",
    "\n",
    "\n",
    "- Maximum Number of iterations (max_iter): If the algorithm doesn't converge prior, this is the maximum number of times the algorithm will loop through re-calculation of the centroids.\n",
    "\n",
    "\n",
    "- random_state: Specific to sklearn, this is for 'setting the seed' for reproducibility. When you use any integer as a value here and then re-run with the same value, the algorithm will kick off with the same seed as before, thus the same observations & centroids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pros\n",
    "\n",
    "\n",
    "1. Performance scales well with the amount of data, i.e. the algorithm is linear in the number of objects $O(n)$\n",
    "\n",
    "2. Creates tighter, more refined clusters\n",
    "\n",
    "3. Centroids can be recomputed driving an observation or object to another cluster\n",
    "\n",
    "\n",
    "- Cons\n",
    "\n",
    "\n",
    "1. naive use of the mean value for the cluster center\n",
    "\n",
    "\n",
    "2. fails when the clusters are not circular\n",
    "\n",
    "\n",
    "3. Hard to predict what k (the number of clusters) should be\n",
    "\n",
    "\n",
    "4. Which observations the clustering starts with, i.e. initial seeds, can dramatically affect the results\n",
    "\n",
    "\n",
    "5. The order of the data can affect the results\n",
    "\n",
    "\n",
    "6. Results are extremely sensitive to the scale of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
